{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeachBoys BikeShare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze workshop is een ML gefocuste versie van de BeachBoys BikeSharing case. In deze case onderzoeken we één van hun bedrijfsproblemen en zorgen we voor een slimme oplossing aan de hand van data.<br>\n",
    "BeachBoys BikeShare is een fiets sharing bedrijf in de Bay Area. Ze hebben verschillende stations met fietsenstallingen waar klanten op elk moment een fiets kunnen huren. Ze kunnen vervolgens de fiets terugbrengen naar eender welk van hun stations.<br>\n",
    "Het probleem waar we op gaan inzoomen vandaag is het optimaal gebruik van hun fietsen. Elk station heeft een bepaalde hoeveelheid stallingen, wanneer er geen fietsen beschikbaar zijn, verliezen we klanten aangezien ze geen trip kunnen maken. Wanneer het station vol is verliezen we klantentevredenheid, aangezien de klanten niet langer kunnen afstappen waar ze willen.<br>\n",
    "Momenteel is er een wagen die voltijds rondrijdt en extra fietsen ophaalt/levert waar nodig, deze rijdt echter louter op goed gevoel. Het zou handig zijn moesten we deze kunnen sturen naar de locaties waar de hulp nodig is. De auto heeft natuurlijk tijd nodig om te navigeren tussen de verschillende stations, we zouden dus een periode op voorhand al moeten kunnen voorspellen waar deze drukke stations zich bevinden. Een ideale taak voor machine learning!<br><br>\n",
    "\n",
    "\n",
    "Korte vraag: Wat voor machine learning model hebben we hiervoor nodig? <br> <br>\n",
    "\n",
    "## Inhoud\n",
    "- Importeer Libraries\n",
    "- Data Analyse\n",
    "   - Station Data\n",
    "   - Trip Data\n",
    "   - Weer Data\n",
    "- Data Transformatie\n",
    "- Model Trainen\n",
    "   - Baseline wiskundig model\n",
    "   - Lineaire regressie\n",
    "   - Ridge regressie\n",
    "   - Decision Tree (Beslissingboom)\n",
    "   - Random Forest\n",
    "   - Gradient Boosting\n",
    "   - Multilayer Perceptron\n",
    "- Visualiseren\n",
    "\n",
    "\n",
    "Tijden het analyseren van de data gaan we jullie zelf laten experimenteren met de verschillende beschikbare data en het plotten ervan om inzichten te creëren.<br>\n",
    "Het transformeren van de data is verdere oefening op het gebruik van pandas om data voor te bereiden voor machine learning modellen.<br>\n",
    "Vervolgens gaan we enkele modellen trainen en evalueren. Hier kunnen we experimenteren met de invloed van verschillende parameters, alsook met het effect van de features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voor we beginnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We beginnen met eerst de nodige data en libraries in te laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import numpy as np\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit commando opent een popup waar je je moet inloggen op je azure account\n",
    "#!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haal data uit een storage container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu we zijn ingelogt kunnen we verbinden met de storage account en vervolgens de data uit de correcte container halen\n",
    "\"\"\"\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "try:\n",
    "    default_credential = DefaultAzureCredential() # regelt de authenticatie\n",
    "\n",
    "    connection_string = \"https://mowworkshopprep.blob.core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient(connection_string,default_credential) #verbinden met de storage account\n",
    "    container_name = \"workshopdata\"\n",
    "    container_client = blob_service_client.get_container_client(container_name) #verbinden met de container\n",
    "\n",
    "    local_path = \"../data\"\n",
    "\n",
    "    blob_list = container_client.list_blobs() #lees alle bestanden in de container\n",
    "    for blob in blob_list: # Ga over alle bestanden (blobs) en schrijf ze weg\n",
    "        blob_client = container_client.get_blob_client(blob.name)    \n",
    "        local_file_path = f\"{local_path}/{blob.name}\"\n",
    "        with open(local_file_path, \"wb\") as local_file:\n",
    "            local_file.write(blob_client.download_blob().readall())\n",
    "    \n",
    "    # Controleer of alle bestanden gedownload zijn\n",
    "    required_files = [\"station_data.csv\", \"trip_data.csv\", \"weather_data.csv\", \"previousValues.csv\"]\n",
    "    for file_name in required_files:\n",
    "        file_path = os.path.join(local_path, file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "            raise FileNotFoundError(f\"{file_name} not found in the local folder.\")\n",
    "    print(\"All required files found in the local folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haal data uit vanuit een data asset op machine learning studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastoreURI = \"azureml://subscriptions/749321d1-c59b-435d-b86b-d37cb334a686/resourcegroups/rg-mow-prepworkshop/workspaces/MOW-WorkshopPrer/datastores/workspaceblobstore/paths/UI/2024-01-26_162051_UTC/\"\n",
    "required_files = [\"station_data.csv\", \"trip_data.csv\", \"weather_data.csv\", \"previousValues.csv\"]\n",
    "for file in required_files:\n",
    "  df = pd.read_csv(f\"{datastoreURI}{file}\")\n",
    "  df.to_csv(f\"../data/{file}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyseer de Tabellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De eerste stap is kijken welke data beschikbaar is, en of hier enkele opvallende trends in te vinden zijn. <br>\n",
    "Het eerste bestand is 'station_data.csv', elke rij hier vertelt meer over een bepaald station: de locatie, het aantal plaatsen voor fietsen,... <br>\n",
    "Het tweede bestand bevat een rij voor elke geregistreerde trip, en geeft aan waar en wanneer deze gestart/ beëindigt zijn. Dit is ook de grootste tabel aangezien het informatie bevat voor elke gemaakte trip.<br>\n",
    "De laatste tabel is informatie over het weer in en rond San Francisco. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(\"../data/station_data.csv\")\n",
    "station_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elk station bevat verschillende gegevens:\n",
    "- id: een unieke getal voor elk station\n",
    "- Name: Naam van het station\n",
    "- Lat: breedtegraad\n",
    "- Long: lengtegraad\n",
    "- Dock count: aantal plaatsen voor fietsen in het station\n",
    "- City: De stad waar het station zich bevind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = station_data.dtypes\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het type 'object' betekent string in dit geval. Alle kolommen staan reeds in de juiste vorm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aantal Stations per stad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data['City'].value_counts().plot(kind=\"bar\")\n",
    "plt.xlabel(\"Stad\")\n",
    "plt.ylabel(\"Aantal Stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totaal aantal fiestplaatsen per stad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocksPerCity = station_data.groupby(['City'])['Dock Count'].sum().reset_index()\n",
    "plt.bar(DocksPerCity['City'],DocksPerCity['Dock Count'])\n",
    "plt.xlabel(\"Stad\")\n",
    "plt.ylabel(\"Totaal aantal fietsplaatsen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nu is het aan Jullie, denk aan statestieken die we nog kunnen gebruiken. Gebruik de datasets naar keuze***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data = pd.read_csv(\"../data/trip_data.csv\")\n",
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elke trip die een persoon maakt bevat de volgende gegevens:\n",
    "- Trip ID: een uniek nummer voor elke trip\n",
    "- Start Date: start tijd en datum van de trip\n",
    "- Start Station: Waar is de trip begonnen\n",
    "- End Date: eind tijd en datum van de trip\n",
    "- End Station: Waar is de trip beëindigd\n",
    "- Subscriber Type: Wat soort abonnement heeft de gebruiker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = trip_data.dtypes\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier zien we dat de start en eind tijd in string formaat staan. Hierdoor kunnen we niet redeneren over tijd, wat een belangrijk aspect is voor het voorspellen van het aantal fietsen. We moeten deze dus eerst transformeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data['Start Date'] = pd.to_datetime(trip_data['Start Date'], format='%d/%m/%Y %H:%M')\n",
    "trip_data['End Date'] = pd.to_datetime(trip_data['End Date'], format='%d/%m/%Y %H:%M')\n",
    "print(trip_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data[\"tripDuration\"] = (trip_data['End Date']-trip_data['Start Date']).dt.total_seconds()/60\n",
    "trip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minDate = trip_data['Start Date'].min()\n",
    "minDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDate = trip_data['End Date'].max()\n",
    "maxDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien nu dat we ongeveer 1 jaar aan data hebben van September 2014 tot en met Augustus 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu zou het ook interessant zijn om naar trends in de tijd te kunnen kijken. Zijn er spitsuren? Is het drukker tijdens het weekend of in de week? Is er een winterstop? Al deze vragen zijn relevant voor het voorspellen waar veel fietsen nodig zijn. <br>\n",
    "Momenteel staan de tijdstippen opgeslagen in 1 kolom, onbewust kunnen wij dit in onze gedachten al opsplitsen in jaren, maanden, dagen, uren,...<br>\n",
    "Maar het machine learning model kan dit niet, ook maakt dit het plotten meer ingewikkeld. Daarom splitsen we nu eerst de tijdstippen op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits Start Date op\n",
    "trip_data['StartYear'] = trip_data['Start Date'].dt.year\n",
    "trip_data['StartMonth'] = trip_data['Start Date'].dt.month\n",
    "trip_data['StartDay'] = trip_data['Start Date'].dt.day\n",
    "trip_data['StartWeekday'] = trip_data['Start Date'].dt.weekday  # Maandag is 0 en zondag is 6\n",
    "trip_data['StartHour'] = trip_data['Start Date'].dt.hour\n",
    "trip_data['StartMinute'] = trip_data['Start Date'].dt.minute\n",
    "\n",
    "# Splits End Date op\n",
    "trip_data['EndYear'] = trip_data['End Date'].dt.year\n",
    "trip_data['EndMonth'] = trip_data['End Date'].dt.month\n",
    "trip_data['EndDay'] = trip_data['End Date'].dt.day\n",
    "trip_data['EndWeekday'] = trip_data['End Date'].dt.weekday  # Maandag is 0 en zondag is 6\n",
    "trip_data['EndHour'] = trip_data['End Date'].dt.hour\n",
    "trip_data['EndMinute'] = trip_data['End Date'].dt.minute\n",
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nu is het aan Jullie, denk aan statestieken die we nog kunnen gebruiken. Gebruik de datasets naar keuze***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(\"../data/weather_data.csv\")\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = weather_data.dtypes\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['Date'] = pd.to_datetime(weather_data['Date'], format='%d/%m/%Y')\n",
    "weather_data = weather_data[weather_data['Zip'] == 94107]\n",
    "weather_data['Events'] = weather_data['Events'].fillna('None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nu is het aan Jullie, denk aan statestieken die we nog kunnen gebruiken. Gebruik de datasets naar keuze***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dit deel bevat enkele lijnen code die nog ingevuld moeten worden, let opde TODO's en vul in waar ... staat.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dat we een beter begrip hebben van de gegevens, is het tijd om de data klaar te maken voor een machine learning model. <br>\n",
    "De data moet 2 onderdelen bevatten voor we ons model kunnen trainen. <br> \n",
    "1. Eerst moeten we een 'Target' hebben, de waarde die we willen voorspellen. In deze opdracht willen we ervoor zorgen dat op elk moment fietsen beschikbaar zijn voor de klanten. We weten niets over het absolute aantal fietsen op een station, dus deze waarde is moeilijk te voorspellen. Wat we wel weten is hoeveel fietsen aankomen en vertrekken op een bepaald station. Hierdoor kunnen we een netto 'verandering aan fietsen' berekenen en ook voorspellen. Deze verandering per uur bekijken lijkt een goeie target, per minuut is te ambitieus en geeft ook geen tijd voor de volgwagen om nieuwe fietsen te leveren waar nodig, en aangezien de meeste trips korter zijn dan één uur gaat per dag een te groot venster zijn. Plaatsen waar we grote veranderingen voorspellen kunnen we de volgauto naartoe sturen, om extra fietsen af/op te laden.<br><br>\n",
    "2. Ten tweede hebben we features nodig die het model kan gebruiken om onze target te voorspellen. De exploratie die we juist gedaan hebben kan hiervoor nuttig zijn alsook onze eigen intuitie. We zagen bijvoorbeeld dat er 2 piek uren rond 8 en rond 17, het uur is dus een belangrijke feature om de 'verandering aan fietsen' te voorspellen. Andere gegevens zoals de dag van de week, de maand, welk station, het weer zijn allemaal zaken die invloed kunnen hebben op 'verandering aan fietsen'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is de data waar we mee zijn geëindigd na de voorgaande analyse. We kunnen deze eerst wat opschonen en de \n",
    "- start/end date \n",
    "- tripDuration \n",
    "- duration_bins\n",
    "- Start/End minuten \n",
    "verwijderen (We voorspellen per uur dus de minuten zijn niet meer nodig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop = ['Start Date','End Date','tripDuration','StartMinute','EndMinute']\n",
    "trip_data = #TODO verwijder de bovenstaande kolommen, hint: gebruik de drop functie\n",
    "\n",
    "trip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als alles goed zit, hebben we nu 14 kolommen aan data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de netto 'verandering in fietsen' op een bepaald station te voorspellen hebben we 2 onderdelen nodig, de fietsen die aankomen in dit station (End Station) en degene die vertrekken vanaf dit station (Start Station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomingBikes = trip_data.groupby(['Start Station', 'StartYear','StartMonth','StartDay','StartHour']).size().reset_index(name='incoming')\n",
    "IncomingBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We weten niet of er op elk uur een fiets vertrekt of aankomt op een bepaald station. Dus we maken eerst een dataset aan die voor elk station alle uren bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=minDate, end=maxDate, freq='H')\n",
    "date_df = pd.DataFrame(date_range, columns=['datetime'])\n",
    "date_df['dateIndex'] = range(len(date_df)) # We voegen een tijdsindex toe, deze gaat ons later helpen\n",
    "\n",
    "stations_df = pd.DataFrame(trip_data['Start Station'].unique(), columns=['Station']) # Extraheer alle verschillende stations\n",
    "stationTime_df = pd.merge(date_df,stations_df,how='cross')\n",
    "stationTime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits de datum terug op\n",
    "#TODO: splits stationTime_df per jaar\n",
    "stationTime_df['year'] =  ...\n",
    "#TODO: splits stationTime_df per maand\n",
    "stationTime_df['month'] = ...\n",
    "#TODO: splits stationTime_df per dag\n",
    "stationTime_df['day'] = ...\n",
    "#TODO: splits stationTime_df per weekdag\n",
    "stationTime_df['weekday'] = ...\n",
    "#TODO: splits stationTime_df per uur\n",
    "stationTime_df['hour'] = ...\n",
    "stationTime_df= stationTime_df.drop('datetime',axis=1)\n",
    "stationTime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomingBikes = pd.merge(stationTime_df, IncomingBikes, left_on=['Station', 'year','month','day','hour'],right_on=['Start Station','StartYear','StartMonth','StartDay','StartHour'] , how='left')\n",
    "IncomingBikes = IncomingBikes.drop(['Start Station','StartYear','StartMonth','StartDay','StartHour'],axis=1)\n",
    "\n",
    "#TODO: Vul de waarde in waar we lege rijen mee opvullen. Als er geen rij beschikbaar was, hoeveel fietsen kwamen er dan aan\n",
    "IncomingBikes['incoming'] = IncomingBikes['incoming'].fillna(...).astype(int)\n",
    "IncomingBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we de aankomende fietsen hebben, doen we hetzelfde voor de vertrekkende fietsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Op welke kolommen gaan we groeperen?\n",
    "OutGoingBikes = trip_data.groupby([...]).size().reset_index(name='outgoing')\n",
    "\n",
    "#TODO: welke tabellen moeten we nu verbinden?\n",
    "OutGoingBikes = pd.merge(..., ..., left_on=['Station', 'year','month','day','hour'],right_on=['End Station','EndYear','EndMonth','EndDay','EndHour'] , how='left')\n",
    "OutGoingBikes = OutGoingBikes.drop(['End Station','EndYear','EndMonth','EndDay','EndHour'],axis=1)\n",
    "\n",
    "#TODO: Vul de waarde in waar we lege rijen mee opvullen. Als er geen rij beschikbaar was, hoeveel fietsen zijn er dan vertrokken?\n",
    "OutGoingBikes['outgoing'] = OutGoingBikes['outgoing'].fillna(...).astype(int)\n",
    "OutGoingBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu moeten we nog het verschil nemen tussen beide om aan het netto verandering van fietsen te komen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChangeInBikes = pd.merge(IncomingBikes,OutGoingBikes,on=['dateIndex','Station','year','month','day','hour','weekday'],how= 'left')\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: bereken de netto verandering aan fietsen\n",
    "ChangeInBikes['netBikeChange'] = ...\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetBikeChange is onze target value en dus de waarde die we willen voorspellen, de overige kolommen zijn al enkele features die we kunnen gebruiken om de voorspelling te maken. Natuurlijk de incoming en outgoing waardes zijn onbekend tijdens het voorspellen, dus die verwijderen we nog eerst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChangeInBikes= ChangeInBikes.drop(['incoming','outgoing'],axis=1)\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kunnen we even nadenken welke andere features nog van pas zouden komen.\n",
    "- Het aantal fiestenstalling in een station\n",
    "- de Stad waarin het station zich bevindt\n",
    "- Is het weekend?\n",
    "- Weer events (regen,mist,...)\n",
    "- Temperatuur\n",
    "- Verandering tijdens de laatste uren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is het weekend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: gebruik de isin functie om weekend dagen aan te duiden in een feature (cast daarna ook de feature naar een int via '.astype(int)')\n",
    "ChangeInBikes['IsWeekend'] = ChangeInBikes[...]. ...\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In welke stad is het station? En hoeveel fiets plaatsen zijn er?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChangeInBikes = pd.merge(ChangeInBikes, station_data, left_on='Station', right_on='Id',how='left')\n",
    "\n",
    "#TODO: verwijder de onnodige kolommen van de data via de drop functie (Id, Lat, Long en Name)\n",
    "ChangeInBikes = ...\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen de stad niet zomaar gebruiken, niet alle modellen kunnen werken met categorie waarden. We zullen deze eerst veranderen via one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: verander de namen van de steden in 1 woord door spaties te verandering in een laag streepje.\n",
    "ChangeInBikes['City'] = ChangeInBikes['City'].str.replace(...,...)\n",
    "\n",
    "citiesEncoded = pd.get_dummies(ChangeInBikes['City'], prefix='City')\n",
    "ChangeInBikes = pd.concat([ChangeInBikes, citiesEncoded], axis=1)\n",
    "\n",
    "ChangeInBikes= ChangeInBikes.drop('City',axis=1)\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperatuur en Weer events?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor we de 2 features over het weer kunnen toevoegen moeten we de datums van de weer tabel aanpassen. Beide datums moeten in dezelfde vorm staan zodat we de tabellen kunnen verbinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['year'] = weather_data['Date'].dt.year\n",
    "weather_data['month'] = weather_data['Date'].dt.month\n",
    "weather_data['day'] = weather_data['Date'].dt.day\n",
    "\n",
    "#TODO: Transformeer de gemiddelde temperatuur van farenheit naar celcius\n",
    "weather_data['Mean TemperatureC'] = (... - 32) * 5/9\n",
    "#TODO: Rond de nieuwe temperaturen af op 2 cijfers na de komma\n",
    "weather_data['Mean TemperatureC'] = weather_data['Mean TemperatureC']. ...\n",
    "\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_features = weather_data[['year','month','day','Mean TemperatureC','Events']]\n",
    "weather_data_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De events moeten ook opgesplitst worden per waarde zoals de steden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: One hot encode de weer events (tip: gelijkaardig als bij de steden, en prefix met 'Event')\n",
    "weatherEncoded = ...\n",
    "weather_data_features = pd.concat([weather_data_features, weatherEncoded], axis=1)\n",
    "weather_data_features= weather_data_features.drop('Events',axis=1)\n",
    "weather_data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: verbind de ChangeInBikes en weather_data_features tabellen via de pd.merge functie.\n",
    "ChangeInBikes = ...\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wat gebeurde er tijdens de vorige uren?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een volgend feature dat kan helpen, is een zeer populaire bij het voorspellen van waarden over tijd (Time series predictions). Namelijk de waarde van het vorige uur (of van de vorige uren). Als we terugdenken aan onze piek uren, herinneren we ons dat drukke periodes niet plots opdaagden, maar geleidelijk op en afbouwt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier komt de tijdsindex terug van pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetChangeFromPreviousHour(df,dateIndex,station,n=1):\n",
    "    if (dateIndex-n) > 0:\n",
    "        prevNetChange = df.loc[(df['dateIndex'] == dateIndex-n) & (df['Station'] == station), 'netBikeChange'].values[0] #loc zoekte specifieke rijen in de data\n",
    "    else:\n",
    "        prevNetChange = 0\n",
    "    return prevNetChange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit zijn zwaardere functies aangezien we over elke rij moeten gaan en vervolgens voor elke rij de vorige waardes opzoeken in de tabel. Daarom is er ook een bestandje toegevoegd dat de nodige waardes al bevat. Door deze te linken aan onze tabel kunnen we wat tijd besparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChangeInBikes['NetBikeChange-1'] = ChangeInBikes.apply(lambda row: getNetChangeFromPreviousHour(ChangeInBikes,row['dateIndex'], row['Station']), axis=1)\n",
    "#ChangeInBikes['NetBikeChange-2'] = ChangeInBikes.apply(lambda row: getNetChangeFromPreviousHour(ChangeInBikes,row['dateIndex'], row['Station'],2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende functie laad het bestand in en voegt de waardes toe aan de feature tabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previousValues = pd.read_csv(\"../data/previousValues.csv\")\n",
    "ChangeInBikes = pd.merge(ChangeInBikes, previousValues, on=['dateIndex','Station'],how='left')\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier voegen we de veranderingen tijdens de vorige 2 uren toe, we kunnen nog meer van deze historische waardes toevoegen, maar we moeten telkens het nut hiervan afwegen. Elk feature dat we toevoegen maakt ons model iets zwaarder. Hoeveel fietsen er 5 uur geleden zijn bijgekomen gaat weinig tot geen invloed hebben op hoeveel fietsen we nu gaan zien aankomen.<br><br>\n",
    "Voor we dit deel afmaken verwijderen we nog even de 'dateIndex', deze was handig voor de vorige waardes toe te voegen maar heeft nu geen nut meer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChangeInBikes = ChangeInBikes.drop('dateIndex',axis=1)\n",
    "ChangeInBikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We eindigen met 22 kolommen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model trainen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het trainen van de modellen bevat geen zelf in te vullen lijnen, maar wel verschillende parameters waarmee geexperimenteerd kan worden. Alsook het aantal features waar we aan kunnen sleutelen. Onderstaande code laat ons toe om een aantal features te kiezen om mee verder te gaan. Indien er genoeg tijd is, raad ik zeker aan om terug naar dit punt te komen en hier mee te experimenteren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChangeInBikes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenteer gerust  met de features in de volgende lijsten\n",
    "weatherColomns= [\"Mean TemperatureC\",\"Event_Fog\",\"Event_Fog-Rain\",\"Event_None\",\"Event_Rain\",\"Event_Rain-Thunderstorm\"]\n",
    "timeColumns = [\"year\",\"month\",\"day\",\"weekday\",\"hour\",\"IsWeekend\",\"NetBikeChange-1\",\"NetBikeChange-2\"]\n",
    "stationColumns = [\"Station\",\"Dock Count\",\"City_Mountain_View\",\"City_Palo_Alto\",\"City_Redwood_City\",\"City_San_Francisco\",\"City_San_Jose\"]\n",
    "\n",
    "\n",
    "selectedColumns = weatherColomns+timeColumns+stationColumns\n",
    "selectedColumns.append(\"netBikeChange\")\n",
    "ML_dataset= ChangeInBikes[selectedColumns]\n",
    "ML_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor we kunnen beginnen modelleren en voorspellingen maken, moeten we de data nog één keer aanpassen. We moeten hem eerst opsplitsen in 2 groepen:<br>\n",
    "De Trainingsdata, die we gebruiken om onze modellen te leren hoe ze onze targetwaarde kunnen voorspellen. Dit is meestal ook het grootste deel van de data, zodat het model betere predicties kan maken.<br>\n",
    "De test data, deze wordt apart gehouden tot het einde om te controleren hoe goed ons model werkt op ongeziene data.<br>\n",
    "Vaak is er nog een derde categorie, de validatie data, deze helpt om bepaalde parameters voor de modellen te kiezen. Vandaag gaan we geen extra parameters afwegen dus we kunnen deze data gebruiken om een grondigere eindevaluatie te voeren.<br><br>\n",
    "Hoeveel data we gebruiken voor elke groep, moeten we zelf afwegen. Een vuistregel is 80/10/10, 80% van de data voor training, 10% voor validatie en 10% voor het testen.<br>\n",
    "Vaak delen we de dataset quasi willekeurig op in de verschillende groepen, op deze manier voorkomen we dat er bijvoorbeeld nooit regen gezien werd in de trainingsdata. Maar in tijdserie voorspellingen, zoals de data waar we momenteel mee bezig zijn, wordt er vaak gesplitst op een bepaalde datum aangezien dit beter de realiteit reflecteert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit geval hebben we bijna een jaar aan data, laten we de eerste 9 maanden gebruiken om te trainen en de overige 2,5 om te testen. Dit zou betekenen dat we splitsen vanaf 1 juni. Alles ervoor is onze training set, alles erna is onze test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = ML_dataset[(ML_dataset['year']==2014) | (ML_dataset['month']< 6)]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df =  ML_dataset[(ML_dataset['year']==2015) & (ML_dataset['month']>= 6)]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eerste wiskundige versie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een goede tip tijdens het trainen van machine learning modellen is om te beginnen met een zeer simpele versie. Deze hoeft niet eens gebruik te maken van machine learning en kan gewoon wiskundig zijn. Op deze manier hebben we een basis, waartegen we de meer geavanceerde versies kunnen vergelijken.<br>\n",
    "In dit geval zou zo een basis bijvoorbeeld kunnen zijn om de gemiddelde 'verandering aan fietsen' te berekenen en altijd deze te voorspellen.<br>\n",
    "Wij gaan voor een iets geavanceerdere versie gaan. Aangezien we de 'verandering aan fietsen' gedurende de vorige 2 momenten hebben, kunnen we de vorige veranderingen berekenen en deze verder zetten tijdens het volgende uur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativePrediction(lastHour,twoHoursAgo):\n",
    "    return lastHour + (lastHour-twoHoursAgo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_deriv_df = test_df.copy()\n",
    "test_deriv_df['predicted'] = test_df.apply(lambda row: derivativePrediction(row['NetBikeChange-1'], row['NetBikeChange-2']), axis=1)\n",
    "test_deriv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "\n",
    "test_MSE = mean_squared_error(test_deriv_df['netBikeChange'],test_deriv_df['predicted'])\n",
    "print(f\"baseline: de MSE error op de test set is: {test_MSE}\")\n",
    "test_RMSE = root_mean_squared_error(test_deriv_df['netBikeChange'],test_deriv_df['predicted'])\n",
    "print(f\"baseline: de MSE error op de test set is: {test_RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze mean square error geeft aan hoeveel fietsen we gemiddeld naast de eigenlijke verandering zitten. Deze baseline geeft aan dat we gemiddeld rond de 10 fietsen fout zitten. Dit is natuurlijk geen geweldig resultaat dus hopelijk kan een machine learning model dit beter dan een simpel wiskundig model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineaire regressie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor we de eigenlijke training doen, moeten we de dataset in een vorm brengen die geaccepteerd wordt door de gebruikte functies. In dit geval maken we gebruik van de [scikit-learn library](https://scikit-learn.org/stable/modules/classes.html), In de documentatie vinden we dat modellen op de volgende manier getraind worden:<br><br>\n",
    "<em> model = LinearRegression().fit(X, y)</em><br><br>\n",
    "Hier staat X voor onze features en y voor onze targetwaarde, dus we moeten eerst onze train en test set splitsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = training_df['netBikeChange']\n",
    "train_df_features = training_df.drop('netBikeChange',axis=1)\n",
    "\n",
    "test_target = test_df['netBikeChange']\n",
    "test_df_features = test_df.drop('netBikeChange',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ons eerste model is een lineaire regressie, deze zal proberen de target waarde te voorspellen als een lineaire combinatie van de verschillende features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_df_features, train_target)\n",
    "\n",
    "predictions= lr.predict(test_df_features)\n",
    "lr_test_MSE = mean_squared_error(test_target,predictions)\n",
    "print(f\"linear regressor: de MSE error op de test set is: {lr_test_MSE}\")\n",
    "lr_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "print(f\"ridge regressor: de MSE error op de test set is: {lr_test_RMSE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben zojuist ons eerste machine learning model kunnen trainen in slechts 2 lijnen code! <br>\n",
    "Deze is al een verbetering ten opzichte van onze baseline, de gemiddelde fout hebben we kunnen verlagen van 10 fietsen naar 2.5 fietsen.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "Nu we een getraind model hebben kunnen we ook eens kijken welke van onze features het belangrijkste zijn tijdens onze voorspellingen.\n",
    "Aangezien lineaire regressie gewoon een lineaire combinatie is van onze features kunnen we hun belang vinden gewoon door te kijken naar hun gewichten, hoe groter deze waarde hoe belangrijker de feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lr.coef_\n",
    "sorted_features = sorted(zip(train_df_features.columns, coefficients), key=lambda x: x[1], reverse=True)\n",
    "print('Feature Coefficients:')\n",
    "for feature, coefficient in sorted_features:\n",
    "    print(f'{feature}: {coefficient}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureImportanceGraph(importanceZip):\n",
    "    sorted_features = sorted(importanceZip, key=lambda x: x[1], reverse=True)\n",
    "    features, importance_values=  zip(*sorted_features)\n",
    "    plt.bar(features, importance_values, color='blue')\n",
    "    plt.xlabel('Features')\n",
    "    plt.xticks(features, rotation= 90)\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title('Feature Importance')\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ =featureImportanceGraph(sorted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we de coeficcienten extraheren krijgen we een globaal overzicht op het belang van de verschillende features. Via SHAP kunnen we inzoomen en de contributie van de features binnen één voorbeeld bekijken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(lr, test_df_features)\n",
    "shap_values = explainer(test_df_features)\n",
    "shap.plots.waterfall(shap_values[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laten we nog wat andere modellen proberen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het volgende model dat we proberen is een variatie op lineaire regressie, namelijk Ridge regressie. Ze werken op een gelijkaardige manier, het verschil is dat Ridge regressie een regularisatie term toevoegt. Deze probeert de verschillende gewichten zo klein mogelijk te houden, wat van pas komt gezien de vorige resultaten. Voor deze regularisatie term is een hyperparameter alpha nodig, deze weegt af tussen de gewichten zo klein mogelijk houden en een accuraat model.<br>\n",
    "\n",
    "De CV (in RidgeCV) staat voor cross-validatie, dit model kiest volgens deze techniek de beste alpha waarde uit een reeks die wij meegeven zonder dat wij een validatie dataset moeten meegeven.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Experimenteer met de alpha waarde\n",
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(train_df_features, train_target)\n",
    "predictions= ridge.predict(test_df_features)\n",
    "ridge_test_MSE = mean_squared_error(test_target,predictions)\n",
    "print(f\"ridge regressor: de MSE error op de test set is: {ridge_test_MSE}\")\n",
    "ridge_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "print(f\"ridge regressor: de MSE error op de test set is: {ridge_test_RMSE}\")\n",
    "\n",
    "coefficients = ridge.coef_\n",
    "ridge_features = sorted(zip(train_df_features.columns, coefficients), key=lambda x: x[1], reverse=True)\n",
    "print('Feature Coefficients:')\n",
    "for feature, coefficient in ridge_features:\n",
    "    print(f'{feature}: {coefficient}')\n",
    "_ = featureImportanceGraph(ridge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alphas = np.logspace(-6, 6, 25)\n",
    "ridgeCV = RidgeCV(alphas=alphas)\n",
    "ridgeCV.fit(train_df_features, train_target)\n",
    "predictions= ridgeCV.predict(test_df_features)\n",
    "ridge_test_MSE = mean_squared_error(test_target,predictions)\n",
    "print(f\"ridgeCV regressor: de MSE error op de test set is: {ridge_test_MSE}\")\n",
    "ridge_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "print(f\"ridgeCV regressor: de MSE error op de test set is: {ridge_test_RMSE}\")\n",
    "\n",
    "coefficients = ridgeCV.coef_\n",
    "ridgeCV_features = sorted(zip(train_df_features.columns, coefficients), key=lambda x: x[1], reverse=True)\n",
    "print('Feature Coefficients:')\n",
    "for feature, coefficient in ridgeCV_features:\n",
    "    print(f'{feature}: {coefficient}')\n",
    "_ = featureImportanceGraph(ridgeCV_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ondanks dat we geen verbetering merken op de test mean squared error in vergelijking met de gewone lineaire regressie, zijn de gewichten van de verschillende features nu overzichtelijker (zonder extreem grote waardes). Hierdoor krijgen we een beter overzicht welke nu van belang zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(ridgeCV, test_df_features)\n",
    "shap_values = explainer(test_df_features)\n",
    "shap.plots.waterfall(shap_values[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens kunnen we ook even kijken naar beslissingsbomen (decision trees), deze werken aan de hand van slimme vragen over de features die de data telkens opdeelt in 2 delen. De voorspelling is afhankelijk van het eindpunt waar we op belanden na het beantwoorden van alle vragen.<br><br>\n",
    "Een belangrijke parameter hier is de diepte van de boom, dit vertelt hoeveel vragen we moeten beantwoorden voor we een antwoord krijgen.<br> \n",
    "Experimenteer maar even met deze diepte en kijk naar het effect op MSE (normale dieptes zitten tussen de 1 en 10). Het is ook mogelijk om de boom uiteindelijk te plotten via de plot_tree functie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "#experimenteer met de diepte\n",
    "decTree = tree.DecisionTreeRegressor(max_depth=10) \n",
    "decTree.fit(train_df_features, train_target)\n",
    "predictions= decTree.predict(test_df_features)\n",
    "decTree_test_MSE = mean_squared_error(test_target,predictions)\n",
    "print(f\"Decision tree: de MSE error op de test set is: {decTree_test_MSE}\")\n",
    "decTree_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "print(f\"Decision tree: de MSE error op de test set is: {decTree_test_RMSE}\")\n",
    "\n",
    "feature_importances = decTree.feature_importances_\n",
    "tree_features = sorted(zip(train_df_features.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "print('Feature Coefficients:')\n",
    "for feature, coefficient in tree_features:\n",
    "    print(f'{feature}: {coefficient}')\n",
    "_ = featureImportanceGraph(tree_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(decTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bij een diepte van 10 zien we al een verbetering in de MSE van 2.5 naar minder dan 2 fietsen. We hebben dus een nieuwe beste versie gevonden! Het plotten van de boom is echter wel onoverzichtelijk geworden.<br>\n",
    "De belangrijkste features waren uiteindelijk:  de 'verandering van fietsen' tijdens het vorige uur, het uur van de dag, het station en het aantal plaatsen voor fietsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(decTree)\n",
    "shap_values = explainer(test_df_features)\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het volgende model dat we gaan uittesten is een random forest regressor. Dit is een ensemble van decision trees (meerdere decision trees), waarbij de resultaten van elke tree samen worden gebracht om het uiteindelijke resultaat te verkrijgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Experimenteer met de max_depth (diepte) en n_estimators (aantal bomen) parameters\n",
    "rf = RandomForestRegressor(max_depth=8, n_estimators=25) \n",
    "rf.fit(train_df_features, train_target)\n",
    "predictions= rf.predict(test_df_features)\n",
    "rf_test_MSE = mean_squared_error(test_target,predictions)\n",
    "print(f\"Random forest: de MSE error op de test set is: {rf_test_MSE}\")\n",
    "rf_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "print(f\"Random forest: de MSE error op de test set is: {rf_test_RMSE}\")\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "rf_features = sorted(zip(train_df_features.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "print('Feature Coefficients:')\n",
    "for feature, coefficient in rf_features:\n",
    "    print(f'{feature}: {coefficient}')\n",
    "_ = featureImportanceGraph(rf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ondanks dat we werken met 24 extra decision trees blijft de performantie op de testset hetzelfde als die met slechts 1 boom. Dit is dus geen goeie keuze voor ons uiteindelijk model.<br>\n",
    "We zien ook terug dezelfde meest belangrijke features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer(test_df_features)\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens kunnen we kijken naar een gradient boost variant. Opnieuw een ensemble van beslissingsbomen zoals random forest, maar hier stemmen de verschillende bomen niet op het eindresultaat. Bij gradient boosting probeert elke boom de fouten van de vorige boom te corrigeren. We krijgen dus een serie van beslissingsbomen\n",
    "Normale gradient boost modellen bevatten ingebouwde functies om het belang van de features te bekijken, maar dit is niet het geval bij de histogram versie. We zullen deze dus opnieuw berekenen aan de hand van permutaties. Een alternatieve manier om de belangen te berekenen. We veranderen telkens de waardes van 1 feature en controleren de invloed op de performantie, hoe groter de invloed hoe belangrijker de feature.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "ensambleTree = HistGradientBoostingRegressor()\n",
    "ensambleTree.fit(train_df_features, train_target)\n",
    "predictions= ensambleTree.predict(test_df_features)\n",
    "tree_test_MSE = mean_squared_error(test_target,predictions)\n",
    "print(f\"GradientBoosting ensamble: de MSE error op de test set is: {tree_test_MSE}\")\n",
    "tree_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "print(f\"GradientBoosting ensamble: de MSE error op de test set is: {tree_test_RMSE}\")\n",
    "\n",
    "# Een alternatieve manier om het belang van de features te berekenen\n",
    "result = permutation_importance(ensambleTree, test_df_features, test_target, n_repeats=5, random_state=42)\n",
    "feature_importances = result.importances_mean\n",
    "ensambleTreeFeatures = sorted(zip(train_df_features.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "for feature, coefficient in ensambleTreeFeatures:\n",
    "    print(f'{feature}: {coefficient}')\n",
    "_ = featureImportanceGraph(ensambleTreeFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit model is een verbetering ten opzichte van de vorige, we krijgen nu een gemiddelde fout van 1.6 fietsen!<br>\n",
    "Er wordt hier ook gebruikgemaakt van verschillende features om het eindresultaat te bekomen, de belangrijkste zijn het uur van de dag, de verandering van fietsen vorig uur en het station zelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(ensambleTree)\n",
    "shap_values = explainer(test_df_features)\n",
    "shap.plots.waterfall(shap_values[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben nu al 2 lineaire modellen en 3 beslissingsbomen getraind. Laten we dan eens kijken naar wat complexere modellen, zoals een neuraal netwerk.Meer specifiek een multilayer perceptron (MLP), MLP betekent gewoon verschillende lagen aan neuronen (of perceptrons) en is de simpelste variant van een neuraal netwerk.<br>\n",
    "De output van iedere neuron is de lineaire combinatie van de outputs van de vorige laag, we voegen non-lineariteit toe door middel van een activatiefunctie toe te passen op de neuron outputs.<br><br>\n",
    "Dit complexere model geeft meer flexibiliteit maar maakt het ook moeilijker om het belang van de verschillende features te vinden (black box). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "# Test verschillende netwerk groottes en dieptes (Gelieve deze wel redelijk te houden zodat de cluster dit aankan)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(32, 16,8),random_state=1, max_iter=5)\n",
    "mlp.fit(train_df_features, train_target)\n",
    "predictions= mlp.predict(test_df_features)\n",
    "mlp_test_MSE = mean_squared_error(test_target,predictions)\n",
    "print(f\"Multilayer perceptron: de MSE error op de test set is: {mlp_test_MSE}\")\n",
    "mlp_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "print(f\"Multilayer perceptron: de MSE error op de test set is: {mlp_test_RMSE}\")\n",
    "\n",
    "# Een alternatieve manier om het belang van de features te berekenen\n",
    "result = permutation_importance(mlp, test_df_features, test_target, n_repeats=5, random_state=42)\n",
    "feature_importances = result.importances_mean\n",
    "MlpFeatures = sorted(zip(train_df_features.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "for feature, coefficient in MlpFeatures:\n",
    "    print(f'{feature}: {coefficient}')\n",
    "_ = featureImportanceGraph(MlpFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ondanks dat we een complexer, non-lineair model gebruiken zien we geen verbetering in performance, integendeel zelfs. Een zo complex mogelijk model op een probleem gooien is dus niet altijd de oplossing.<br>\n",
    "De verandering van fietsen tijdens het vorige uur is hier veruit het belangrijkste feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualiseer de resultaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu hebben we enkele modellen getraind en klaar voor gebruik binnen het beachboys bikesharing bedrijf. Alhoewel sommige van deze modellen al een redelijke prestatie halen, is er altijd ruimte voor verbetering. Net zoals bij de start van de workshop, beginnen we hier aan door inzichten te krijgen in de data. Hier zijn nu de voorspellingen gemaakt door de verschillende modellen bij gekomen. We kunnen eens kijken hoe deze afwegen tegen de realiteit, en zo leren waar ze in de mist gaan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst kiezen we een bepaalde dag en station uit de test set om te plotten (tussen 1 juni en 14 augustus):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenteer maar met deze waardes\n",
    "station = 70 #dit is een vrij druk station\n",
    "maand = 8\n",
    "dag= 11\n",
    "\n",
    "viz_data = test_df[(test_df['Station']== station)&(test_df['day']== dag)&(test_df['month']== maand)]\n",
    "viz_data_target = viz_data['netBikeChange']\n",
    "viz_data_features = viz_data.drop('netBikeChange',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende code genereert een plot voor ons, we kiezen zelf gewooon het te gebruiken model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model type: variabele met getraind model**<br>\n",
    "Lineaire regressie: lr <br>\n",
    "Ridge regression: ridgeCV <br>\n",
    "Decision tree: decTree<br>\n",
    "Random forest: rf <br>\n",
    "Gradient Boosting: ensambleTree <br>\n",
    "multilayer perceptron: mlp <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test verschillende modellen uit\n",
    "model = lr\n",
    "\n",
    "predictions = model.predict(viz_data_features)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(viz_data_features['hour'],predictions, label ='Predictions',color='r')\n",
    "plt.bar(viz_data_features['hour'], viz_data_target, label='Actual')\n",
    "plt.xlabel('Uur van de dag')\n",
    "plt.xticks(viz_data_features['hour'])\n",
    "plt.ylabel('Verandering van fietsen')\n",
    "plt.title(f'Voorspelling vs Realiteit')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adding origin lines (axes lines)\n",
    "plt.axhline(0, color='black',linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellen evalueren\n",
    "MLflow is een open-source platform dat helpt bij het ontwikkelen, opzetten en onderhouden van machine learning modellen. Het creeert een overview van een specifiek model en kan verschillende zaken bijhouden. Zoals het model zelf, verschillende parameters gebruikt om het model af te stellen, en meetwaardes gevonden tijdens het trainen en testen van het model. <br>\n",
    "Op deze manier kunnen we een duidelijk overzicht houden van alle modellen, alsook vergelijking maken tussen de verschillende versies.<br>\n",
    "MLflow heeft een eigen UI die lokaal geopend kan worden, en is ook geintegreerd met Azure ML. <br>\n",
    "MLflow werkt met runs, een run is één werkprocess dat we gaan opvangen, dit kan het trainen van een bepaald model zijn of gewoon enkele parameters. Deze runs kunnen we dan groeperen binnen een experiment om te vergelijken.<br>\n",
    "Binnen AzureML, vinden we in de jobs tab, al onze MLflow experimenten en runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Een eerste run loggen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"workshop_v1\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Start een run, het trainen van 1 model\n",
    "with mlflow.start_run(run_name= \"First Test\"):\n",
    "    Name = \"Bram\"\n",
    "    mlflow.log_param(\"Test Param\",Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Een model manueel loggen\n",
    "We gaan de eerdere decicion tree nogmaals trainen en deze keer gaan we manueel de verschillende parameters en meetwaarden opslaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start een experiment, groupeert verschillende runs\n",
    "experiment_name = \"workshop_v1\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Start een run, het trainen van 1 model\n",
    "with mlflow.start_run(run_name= \"Tree_Manual\"):\n",
    "\n",
    "    # De hyperparameter die we gaan opslaan\n",
    "    depth = 10\n",
    "    mlflow.log_param(\"Tree depth\", depth)\n",
    "\n",
    "    # Gekopieerde code van de vorige modellen\n",
    "    decTree = tree.DecisionTreeRegressor(max_depth=depth) \n",
    "    decTree.fit(train_df_features, train_target)\n",
    "    predictions= decTree.predict(test_df_features)\n",
    "    \n",
    "    # dit is hoe we manueel ons model opslaan, een makkelijkere manier zien we direct\n",
    "    #signature = infer_signature(train_df_features, decTree.predict(train_df_features))\n",
    "    #mlflow.sklearn.log_model(decTree, \"decision_tree_regressor\", signature=signature)\n",
    "\n",
    "    decTree_test_MSE = mean_squared_error(test_target,predictions)\n",
    "    print(f\"Decision tree: de MSE error op de test set is: {decTree_test_MSE}\")\n",
    "    mlflow.log_param(\"test_MSE\",decTree_test_MSE) # Neem ook deze parameter mee in het overzicht\n",
    "    \n",
    "    decTree_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "    print(f\"Decision tree: de RMSE error op de test set is: {decTree_test_RMSE}\")\n",
    "    mlflow.log_param(\"test_MSE\",decTree_test_MSE) # Neem ook deze parameter mee in het overzicht\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## een model automatisch loggen\n",
    "MLflow laat ook automatisch loggen toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start een experiment, groupeert verschillende runs\n",
    "experiment_name = \"workshop_v1\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Start een run, het trainen van 1 model\n",
    "with mlflow.start_run(run_name= \"Tree_autolog_Only\"):\n",
    "    #Log automatisch alle zaken over het model\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    depth = 10\n",
    "    # Gekopieerde code van de vorige modellen\n",
    "    decTree = tree.DecisionTreeRegressor(max_depth=depth) \n",
    "    decTree.fit(train_df_features, train_target)\n",
    "    predictions= decTree.predict(test_df_features)\n",
    "    \n",
    "    decTree_test_MSE = mean_squared_error(test_target,predictions)\n",
    "    print(f\"Decision tree: de MSE error op de test set is: {decTree_test_MSE}\")\n",
    "\n",
    "    decTree_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "    print(f\"Decision tree: de RMSE error op de test set is: {decTree_test_RMSE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combineer beide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start een experiment, groupeert verschillende runs\n",
    "experiment_name = \"workshop_v1\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Start een run, het trainen van 1 model\n",
    "with mlflow.start_run(run_name= \"Tree_autolog_v1\"):\n",
    "    mlflow.sklearn.autolog() #Log automatisch alle zaken over het model\n",
    "\n",
    "    depth = 10\n",
    "    mlflow.log_param(\"Tree depth\", depth)\n",
    "    \n",
    "    # Gekopieerde code van de vorige modellen\n",
    "    decTree = tree.DecisionTreeRegressor(max_depth=depth) \n",
    "    decTree.fit(train_df_features, train_target)\n",
    "    predictions= decTree.predict(test_df_features)\n",
    "    \n",
    "    decTree_test_MSE = mean_squared_error(test_target,predictions)\n",
    "    print(f\"Decision tree: de MSE error op de test set is: {decTree_test_MSE}\")\n",
    "    mlflow.log_param(\"test_MSE\",decTree_test_MSE) # Neem ook deze parameter mee in het overzicht\n",
    "\n",
    "    decTree_test_RMSE = root_mean_squared_error(test_target,predictions)\n",
    "    print(f\"Decision tree: de RMSE error op de test set is: {decTree_test_RMSE}\")\n",
    "    mlflow.log_param(\"test_RMSE\",decTree_test_RMSE) # Neem ook deze parameter mee in het overzicht\n",
    "\n",
    "    feature_importances = decTree.feature_importances_\n",
    "    tree_features = sorted(zip(train_df_features.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "    fig = featureImportanceGraph(tree_features)\n",
    "    mlflow.log_figure(fig, \"feature_importance.png\") # Neem ook de grafiek mee in het overzicht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi step training proces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"workshop_v1_training_logging\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name= \"MLP_splitTraining_v1\"):\n",
    "  mlflow.sklearn.autolog()\n",
    "  mlp = MLPRegressor(hidden_layer_sizes=(8, 4),random_state=1, max_iter=1)\n",
    "  num_epochs = 20\n",
    "  for epoch in range(num_epochs):\n",
    "     mlp.partial_fit(train_df_features, train_target)\n",
    "     y_pred = mlp.predict(train_df_features)\n",
    "     mse = mean_squared_error(train_target, y_pred)\n",
    "     mlflow.log_metric(\"train_mean_squared_error\", mse)\n",
    "     \n",
    "  predictions= mlp.predict(test_df_features)\n",
    "  mlp_test_MSE = mean_squared_error(test_target,predictions)\n",
    "  print(f\"Gradient descent: de MSE error op de test set is: {mlp_test_MSE}\")\n",
    "  mlflow.log_metric(\"test_mean_squared_error\", mlp_test_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [(8,4),(16,8),(4,2)]\n",
    "for hidden_layer in hidden_layers:\n",
    "    with mlflow.start_run(run_name= f\"MLP_hyper_{hidden_layer}\"):\n",
    "        mlflow.sklearn.autolog()\n",
    "        mlp =  MLPRegressor(hidden_layer_sizes=hidden_layer,random_state=1, max_iter=15)\n",
    "        mlp.fit(train_df_features, train_target)\n",
    "        predictions= mlp.predict(test_df_features)\n",
    "        mlp_test_MSE = mean_squared_error(test_target,predictions)\n",
    "        print(f\"Gradient descent: de MSE error op de test set is: {mlp_test_MSE}\")\n",
    "        mlflow.log_metric(\"test_mean_squared_error\", mlp_test_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nu is het aan jullie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start een experiment, groupeert verschillende runs\n",
    "experiment_name = \"workshop_v1_sandbox\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Start een run, het trainen van 1 model\n",
    "with mlflow.start_run(run_name= \"sandbox_v1\"):\n",
    "    #Log automatisch alle zaken over het model\n",
    "    mlflow.sklearn.autolog() \n",
    "    \n",
    "    #log parameters\n",
    "    mlflow.log_param(\"\", )\n",
    "    \n",
    "    # Train een model\n",
    "  \n",
    "    \n",
    "    #log meetwaardes\n",
    "    mlflow.log_param(\"\",) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
